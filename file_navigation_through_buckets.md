# How the VM works and files are located

Ref: https://support.terra.bio/hc/en-us/articles/360034335332-Understanding-data-in-the-Cloud

<img src="https://support.terra.bio/hc/article_attachments/12777390710043" alt="Overview" width="600" height="600">


**1. External cloud storage**

- like public database storage, CCLE, TCGA, GTEx, etc.

**2. Workspace cloud storage (Google bucket)**

- Each Terra workspace comes with a dedicated storage container (Google bucket), optimized for storing unstructured objects.

- When clone or create a workspace, it will generate the google bucket id for this workspace, to lookup/access, once Juypeter-notebook is create

```
import os
BUCKET = os.environ['WORKSPACE_BUCKET']
```

and it can be view by

```
!echo $BUCKET
```

You can upload primary data stored locally to your workspace storage for analysis in Terra. If you need to upload data to workspace storage

- Data generated by a workflow analysis (WDLs) are stored by default in workspace cloud storage (Google bucket).
  
- You pay the Google storage cost for data in your workspace storage bucket.


**3. persistent disk (PD)**

- When you spin up a cloud environment VM, you'll set the storage size and type of your detachable persistent disk (PD).
  
- When running Galaxy, Jupyter Notebooks, or RStudio, the generated output is stored in your PD by default.

- You pay the GCP cost (per month) of the PD you select. You can see how much you are paying for persistent disk storage in your Cloud Environments page (Profile > Cloud Environments).


**Move files**

use gcp command

copy files from PD to workspace cloud storage if needed 

```
!gsutil cp {files} $BUCKET
```




